\protect \hypertarget {soln:1.1}{}
\newcommand{\Var}[1]{\operatorname{Var}{\left(#1\right)}}
\newcommand{\E}[1]{\mathbb{E}{\left(#1\right)}}
\newcommand{\Cov}[2]{\operatorname{Cov}{\left(#1, #2\right)}}

\begin{solution}{{1.1}}
В данном случае статистика $DW$ не применима, так как есть лаг $y_{t-1}$ среди регрессоров.
\end{solution}
\protect \hypertarget {soln:1.2}{}
\begin{solution}{{1.2}}
\begin{enumerate}
\item $\E(\e_t)=0$, $\Var(\e_1)=\sigma^2$, $\Var(\e_t)=2\sigma^2$ при $t\geq 2$.  Гетероскедастичная.
\item $\Cov(e_t,e_{t+1})=\sigma^2$. Автокоррелированная.
\item $\hb$ --- несмещенная, неэффективная
\item Более эффективной будет $\hb_{gls}=(X'V^{-1}X)^{-1}X'V^{-1}y$, где
\[
X=\begin{pmatrix}
x_1 \\
x_2 \\
\vdots \\
x_n
\end{pmatrix}
\]

Матрица $V$ известна с точностью до константы $\sigma^2$, но в формуле для $\hb_{gls}$ неизвестная $\sigma^2$ сократится.

Другой способ построить эффективную оценку --- применить МНК к преобразованным наблюдениям, т.е. $\hb_{gls}=\frac{\sum x'_i y'_i}{\sum x_i^{\prime 2}}$, где $y'_1=y_1$, $x'_1=x_1$, $y'_t=y_t-y_{t-1}$, $x'_t=x_t-x_{t-1}$ при $t\geq 2$.
\end{enumerate}
\end{solution}
\protect \hypertarget {soln:1.3}{}
\begin{solution}{{1.3}}

Для простоты закроем глаза на малое количество наблюдений и как индейцы пираха будем считать, что пять --- это много.

\end{solution}
\protect \hypertarget {soln:1.4}{}
\begin{solution}{{1.4}}
1. Поскольку имеют место соотношения $\varepsilon_1 = \rho \varepsilon_0 + u_1$ и $Y_1 =\mu + \varepsilon_1$, то из условия задачи получаем, что $\varepsilon_1 \sim N(0,\sigma^2 / (1 - \rho^2))$
и $Y_1 \sim N(\mu,\sigma^2 / (1 - \rho^2))$. Поэтому
\[
f_{Y_1}(y_1) = \frac{1}{\sqrt{2\pi\sigma^2/(1-\rho^2)}}\exp{\left(-\frac{(y_1 - \mu)^2}{2\sigma^2/(1 - \rho^2)}\right)}.
\]

Далее, найдем $f_{Y_2|Y_1}(y_2|y_1)$. Учитывая, что $Y_2 = \rho Y_1 + (1- \rho) \mu + u_2$, получаем $Y_2|\{Y_1 = y_1\} \sim N(\rho y_1 + (1- \rho) \mu, \sigma^2)$. Значит,
\[
f_{Y_2|Y_1}(y_2|y_1) = \frac{1}{\sqrt{2\pi\sigma^2}}\exp{\left(-\frac{(y_2 - \rho y_1 - (1- \rho) \mu)^2}{2\sigma^2}\right)}.
\]

Действуя аналогично, получаем, что для всех $t \geq 2$ справедлива формула
\[
f_{Y_{t}|Y_{t-1}}(y_{t}|y_{t-1}) = \frac{1}{\sqrt{2\pi\sigma^2}}\exp{\left(-\frac{(y_{t} - \rho y_{t-1} - (1- \rho) \mu)^2}{2\sigma^2}\right)}.
\]

Таким образом, находим функцию правдоподобия
\[
\mathrm{L}(\mu, \rho, \sigma^2) = f_{Y_T,\ldots,Y_1}(y_T,\dots,y_1) = f_{Y_1}(y_1)\prod_{t=2}^{T}f_{Y_t|Y_{t-1}}(y_t|y_{t-1}) \text{,}
\]
где $f_{Y_1}(y_1)$ и $f_{Y_t|Y_{t-1}}(y_t|y_{t-1})$ получены выше.

2. Для нахождения неизвестных параметров модели запишем логарифмическую условную функцию правдоподобия:
\[
l(\mu, \rho, \sigma^2|Y_1 = y_1) = \sum_{t=2}^{T}\log{f_{Y_t|Y_{t-1}}(y_t|y_{t-1})} =
\]
\[
=-\frac{T-1}{2} \log(2 \pi) - \frac{T-1}{2} \log{\sigma^2} - \frac{1}{2\sigma^2} \sum_{t=2}^{T}(y_t - \rho y_{t-1} - (1 - \rho) \mu)^2 \text{.}
\]

Найдем производные функции $l(\mu, \rho, \sigma^2|Y_1 = y_1)$ по неизвестным параметрам:
\[
\frac{\partial l}{\partial \mu} = -\frac{1}{2\sigma^2} \sum_{t=2}^{T} 2(y_t - \rho y_{t-1} - (1 - \rho) \mu) \cdot (\rho - 1) \text{,}
\]
\[
\frac{\partial l}{\partial \rho} = -\frac{1}{2\sigma^2} \sum_{t=2}^{T} 2(y_t - \rho y_{t-1} - (1 - \rho) \mu) \cdot (\mu - y_{t-1}) \text{,}
\]
\[
\frac{\partial l}{\partial {\sigma^2}} =  - \frac{T-1}{2\sigma^2} + \frac{1}{2\sigma^4} \sum_{t=2}^{T}(y_t - \rho y_{t-1} - (1 - \rho) \mu)^2 \text{.}
\]

Оценки неизвестных параметров модели могут быть получены как решение следующей системы уравнений:
\[
\left\{
  \begin{aligned}
    \frac{\partial l}{\partial \mu} = 0 \text{,} \\
    \frac{\partial l}{\partial \rho} = 0 \text{,} \\
    \frac{\partial l}{\partial {\sigma^2}} = 0 \text{.}
  \end{aligned}
\right.
\]

Из первого уравнения системы получаем, что
\[
\sum_{t=2}^{T}y_{t} - \hat{\rho} \sum_{t=2}^{T}y_{t-1} = (T - 1) (1- \hat{\rho}) \hat{\mu} \text{,}
\]
откуда
\[
\hat{\mu} = \frac{\sum_{t=2}^{T}y_{t} - \hat{\rho} \sum_{t=2}^{T}y_{t-1}}{(T - 1) (1- \hat{\rho})} = \frac{3 - \hat{\rho} \cdot 3}{4\cdot(1-\hat{\rho})} = \frac{3}{4} \text{.}
\]

Далее, если второе уравнение системы переписать в виде
\[
\sum_{t=2}^{T}(y_t - \hat{\mu} - \hat{\rho} (y_{t-1} - \hat{\mu}))(y_{t-1} - \hat{\mu}) = 0 \text{,}
\]
то легко видеть, что
\[
\hat{\rho} = \frac{\sum_{t=2}^{T}(y_t - \hat{\mu})(y_{t-1} - \hat{\mu})}{\sum_{t=2}^{T}(y_{t-1} - \hat{\mu})^2} \text{.}
\]
Следовательно, $\hat{\rho} =-1/11= -0.0909$.

Наконец, из третьего уравнения системы
\[
\hs^2 =\frac{1}{T-1} \sum_{t=2}^{T}(y_t - \hat{\rho} y_{t-1} - (1 - \hat{\rho}) \hat{\mu})^2 \text{.}
\]
Значит, $\hs^2 = 165/242= 0.6818$. Ответы: $\hat{\mu} = 3/4= 0.75$, $\hat{\rho} = -1/11=-0.0909$, $\hs^2 =165/242=0.6818$.
\end{solution}
\protect \hypertarget {soln:1.5}{}
\begin{solution}{{1.5}}
Несмещёнными остаются. Состоятельными не всегда остаются, например, состоятельность исчезает, если все случайные ошибки тождественно равны между собой.

\end{solution}
\protect \hypertarget {soln:1.6}{}
\begin{solution}{{1.6}}
\end{solution}
\protect \hypertarget {soln:1.7}{}
\begin{solution}{{1.7}}
\end{solution}
\protect \hypertarget {soln:1.8}{}
\begin{solution}{{1.8}}
\end{solution}
\protect \hypertarget {soln:1.9}{}
\begin{solution}{{1.9}}
\begin{enumerate}
\item $\E(\e_t)=0$, $\Var(\e_t)=\sigma^2/(1-\rho^2)$
\item $\Cov(\e_t,\e_{t+h})=\rho^h\cdot \sigma^2/(1-\rho^2)$
\item $\Corr(\e_t,\e_{t+h})=\rho^h$
\end{enumerate}
\end{solution}
\protect \hypertarget {soln:1.10}{}
\begin{solution}{{1.10}}
\end{solution}
\protect \hypertarget {soln:1.11}{}
\begin{solution}{{1.11}}
\end{solution}
\protect \hypertarget {soln:1.12}{}
\begin{solution}{{1.12}}
\end{solution}
\protect \hypertarget {soln:1.13}{}
\begin{solution}{{1.13}}
\end{solution}
\protect \hypertarget {soln:1.14}{}
\begin{solution}{{1.14}}
\end{solution}
\protect \hypertarget {soln:1.15}{}
\begin{solution}{{1.15}}
\end{solution}
\protect \hypertarget {soln:2.1}{}
\begin{solution}{{2.1}}
\[
(1 - 0.4L)y_t = 4 + (1 + 0.3L)\e_t
\]
\end{solution}
\protect \hypertarget {soln:2.2}{}
\begin{solution}{{2.2}}
$x_{t}=(1-L)^{t}y_{t}$
\end{solution}
\protect \hypertarget {soln:2.3}{}
\begin{solution}{{2.3}}
$ F_{n}=L(1+L)F_{n} $, значит $ F_{n}=L^{k}(1+L)^{k}F_{n} $ или $ F_{n+k}=(1+L)^{k}F_{n} $

Ответ: $1$
\end{solution}
\protect \hypertarget {soln:2.4}{}
\begin{solution}{{2.4}}
а — неверно, б — верно, в — верно, г — нет.
\end{solution}
\protect \hypertarget {soln:2.5}{}
\begin{solution}{{2.5}}
а, б, в, г — стационарны
\end{solution}
\protect \hypertarget {soln:2.6}{}
\begin{solution}{{2.6}}
Они будут примерно одинаковы. Оценка наклона определяется автоковариационной функцией.
\end{solution}
\protect \hypertarget {soln:2.7}{}
\begin{solution}{{2.7}}

\end{solution}
\protect \hypertarget {soln:2.8}{}
\begin{solution}{{2.8}}

\begin{enumerate}
\item $y_t=1+\e_t+0.5\e_{t-1}+0.25\e_{t-2}$ — стационарный
\item $y_t=-2y_{t-1}-3y_{t-2}+\e_t+\e_{t-1}$
\item $y_t=-0.5y_{t-1} + \e_t$ — стационарный
\item $y_t=1-1.5 y_{t-1} - 0.5 y_{t-2} + \e_t - 1.5\e_{t-1} - 0.5\e_{t-2}$
\item $y_t=1+0.64y_{t-2}+\e_t+0.64\e_{t-1}$ — стационарный
\item $y_t=1+t+\e_t$ — нестационарный
\item $y_t=1+y_{t-1}+\e_t$ — нестационарный
\end{enumerate}
\end{solution}
\protect \hypertarget {soln:2.9}{}
\begin{solution}{{2.9}}
Процесс стационарен только при $y_1=4+\frac{2}{\sqrt{3}}\e_1$. Фразу нужно понимать как «у стохастического разностного уравнения $y_t=2+0.5y_{t-1}+\e_t$ есть стационарное решение».
\end{solution}
\protect \hypertarget {soln:2.10}{}
\begin{solution}{{2.10}}
да, стационарный
\end{solution}
\protect \hypertarget {soln:2.11}{}
\begin{solution}{{2.11}}
да, получается
\end{solution}
\protect \hypertarget {soln:2.12}{}
\begin{solution}{{2.12}}
да, это белый шум. Величина $N$ распределена биномиально, $Bin(n=100,p=1/2)$, $\E(N)=50$.
\end{solution}
\protect \hypertarget {soln:2.13}{}
\begin{solution}{{2.13}}

\begin{enumerate}
  \item $z_t = x_t (1-x_{t-1})y_t$;
    Процесс $z_t$ — белый шум, $\E(z_t)=0$, $\Var(z_t)=6$. Величины $z_t$ зависимы. Например, если $z_t \neq 0$, то $z_{t+1}=z_{t-1}=0$. Величины $z_t$ одинаково распределены.
\item $z_t = y_{t-1}y_t$;
Процесс $z_t$ — белый шум. Величины $z_t$ зависимы. Величины $z_t$ одинаково распределены.
\end{enumerate}


\end{solution}
\protect \hypertarget {soln:2.14}{}
\begin{solution}{{2.14}}
Проекции: $\tilde X_1 = X_1 + Z$; $\tilde X_2 = X_2 + Z$; $\E(X_i|Z)=1-Z$; $\Cov(X_i, Z)=-1/4$;

Величина $Z$ имеет распределение Бернулли, поэтому $\E(Z)=1/2$ и $\Var(Z)=1/4$;

\[
  \pCorr(X_1, X_2; Z) = \frac{-1/2}{12.5} = -\frac{1}{\sqrt{50}}
\]
\[
  \Corr(X_1, X_2|Z)=-Z/6
\]
  
\end{solution}
\protect \hypertarget {soln:2.15}{}
\begin{solution}{{2.15}}
\begin{enumerate}
  \item $u_t \sim \cN(0;1)$ и независимы;
  \item $u_t \sim \cN(0;1)$ и независимы при $t>1$, а при $t=1$ величина $u_t$ равновероятно
  принимает значения $-1$ и $1$;
  \item Величины $u_t$ независимы и одинаково распределены с бесконечным математическим ожиданием;
  \item $u_t \sim \cN(t;1)$ и независимы.
\end{enumerate}
\end{solution}
\protect \hypertarget {soln:2.16}{}
\begin{solution}{{2.16}}
  \begin{enumerate}
  \item $\P(z_t = 1) = 2/3$;
  \item $\E(s_t) = (t-2) \cdot 2/3$;
  \item $\Cov(z_1, z_2)$, $\Cov(z_1, z_3)$, $\Cov(z_1, z_4) = 0$;
  \item $\Var(s_t) = (16t - 29)/90$;
  \end{enumerate}

\end{solution}
\protect \hypertarget {soln:2.17}{}
\begin{solution}{{2.17}}
\begin{enumerate}
  \item Процесс $(x_t)$ не обязательно стационарен;
\item Процесс $(y_t)$ не обязательно стационарен;
\item Если любые корреляции равны нулю, то процесс-сумма будет стационарным, а процесс-произведение — не обязательно.
\end{enumerate}
\end{solution}
\protect \hypertarget {soln:3.1}{}
\begin{solution}{{3.1}}

\end{solution}
\protect \hypertarget {soln:3.2}{}
\begin{solution}{{3.2}}

ARMA(2,3), ARIMA(2,0,3)
\end{solution}
\protect \hypertarget {soln:3.3}{}
\begin{solution}{{3.3}}
\begin{enumerate}
\item Процесс $AR(2)$, т.к. две первые частные корреляции значимо отличаются от нуля, а гипотезы о том, что каждая последующая равна нулю не отвергаются.
\item Можно использовать одну из двух статистик
\[
\text{Ljung-Box}=n(n+2)\sum_{k=1}^3\frac{\hat{\rho}_k^2}{n-k}=
0.42886
\]
\[
\text{Box-Pierce}=n\sum_{k=1}^3\hat{\rho}_k^2=
0.4076
\]
Критическое значение хи-квадрат распределения с 3-мя степенями свободы для $\alpha=0.05$ равно $\chi^2_{3,crit}=7.81$.
Вывод: гипотеза $H_0$ об отсутствии корреляции ошибок модели не отвергается.
\end{enumerate}
\end{solution}
\protect \hypertarget {soln:3.4}{}
\begin{solution}{{3.4}}

\end{solution}
\protect \hypertarget {soln:3.5}{}
\begin{solution}{{3.5}}
Среднее количество пересечений равно 50 помножить на вероятность того, что два соседних $y_t$ разного знака. Найдём вдвое меньшую вероятность, $\P(y_1>0, y_2 <0)$.
\end{solution}
\protect \hypertarget {soln:3.6}{}
\begin{solution}{{3.6}}

\[
\E(b_t) = 3
\]

\[
\Var(b_t) = t^2 \sigma^2_{\e}
\]

\[
\Cov(b_t, b_{t-k}) = 0, k \geq 1
\]

\[
\Corr(b_t, b_{t-k}) = 0, k \geq 1
\]

$b_t$ — нестационарный из-за дисперсии


\[
\E(c_t) = 2
\]

\[
\Var(c_t) = \sigma^2_{\e}
\]

\[
\Cov(c_t, c_{t-k}) = \cos( \pi k /2)\sigma^2_{\e}, k \geq 1
\]

\[
\Corr(c_t, c_{t-k}) = \cos( \pi k /2), k \geq 1
\]

$c_t$ — стационарный
\end{solution}
\protect \hypertarget {soln:3.7}{}
\begin{solution}{{3.7}}
зачеркнуть одну цифру
\end{solution}
\protect \hypertarget {soln:3.8}{}
\begin{solution}{{3.8}}
\end{solution}
\protect \hypertarget {soln:3.9}{}
\begin{solution}{{3.9}}
\end{solution}
\protect \hypertarget {soln:3.10}{}
\begin{solution}{{3.10}}
По нулевым корреляциям догадываемся, что это процесс $MA(2)$.
\[
y_y = 4 + u_t + \alpha_1 u_{t-1} + \alpha_2 u_{t-2}
\]
\[
\begin{cases}
  \frac{\alpha_1 \alpha_2 + \alpha_1}{\alpha_2} = 7/3 \\
  \frac{\alpha_1^2 + \alpha_2^2 + 1}{\alpha_2} = 10/3 \\
\end{cases}
\]


\end{solution}
\protect \hypertarget {soln:3.11}{}
\begin{solution}{{3.11}}
\end{solution}
\protect \hypertarget {soln:3.12}{}
\begin{solution}{{3.12}}
  \begin{enumerate}
    \item $ACF = (0.9, -0.9, 0, 0, 0, \ldots)$ не бывает, так как определитель корреляционной матрицы 3 на 3 отрицательный;
    \item $PACF = (0.9, -0.9, 0, 0, 0, \ldots)$ — AR(2);
    \item $PACF = (0.9, 0, 0, 0, 0, \ldots)$ — $y_t = 0.9y_{t-1} + u_t$;
    \item $PACF = (0, 0.9, 0, 0, 0, 0, \ldots)$ — $y_t = 0.9y_{t-2} + u_t$;
    \item $ACF = (0.9, 0, 0, 0, 0, \ldots)$ — не бывает, подозрение падает на MA(1), но решения только с комплексными коэффициентами, геометрически: два угла с косинусом 0.9, то есть примерно по 30 градусов, и они даже в сумме не могут дать перпендикуляр;
    \item $ACF = (0, 0.9, 0, 0, 0, 0, \ldots)$ — не бывает, если проредить процесс через один, то должна получится невозможная ACF;
  \end{enumerate}
   В целом PACF может быть любая,
   \url{http://projecteuclid.org/euclid.aos/1176342881}.
\end{solution}
\protect \hypertarget {soln:3.13}{}
\begin{solution}{{3.13}}
  $\phi_{kk}=0$ при $k \geq 3$.
\end{solution}
\protect \hypertarget {soln:3.14}{}
\begin{solution}{{3.14}}
Заметим, что $0.69\approx 0.71$, сокращаем множитель $1-0.7L$, получаем $y_t = 100/3 + \e_t$.
\end{solution}
\protect \hypertarget {soln:3.15}{}
\begin{solution}{{3.15}}
Стационарным решением является $y_t = \sum_{i=0}^{\infty} 0.5^i \e_{t-i}$. Решениями также являются: $y_t = 0.5^t + \sum_{i=0}^{\infty} 0.5^i \e_{t-i}$, $y_t = 0.5^t\e_{100} + \sum_{i=0}^{\infty} 0.5^i \e_{t-i}$, $y_t = 0.5^t + \sum_{i=0}^{t} 0.5^i \e_{t-i}$, $y_t = \sum_{i=0}^{t} 0.5^i \e_{t-i}$.
\end{solution}
\protect \hypertarget {soln:3.16}{}
\begin{solution}{{3.16}}

$\E_t(y_{t+1})=2+0.6y_{t-1}-0.08y_{t-2}$, $\Var_t(y_{t+1})=4$

$\E_t(y_{t+2})=3.2 + 0.28 y_t- 0.048y_{t-1}$, $\Var_t(y_{t+2})=1.36 \cdot 4$

$\E_{100}(y_{102})= 4.388$, $\Var_{100}(y_{102})=5.44$.

Предиктивный интервал $[4.388 - 1.96 \sqrt{5.44};4.388 + 1.96 \sqrt{5.44}]$

$\E(y_t)=\frac{2}{0.48}\approx 4.17$

\end{solution}
\protect \hypertarget {soln:3.17}{}
\begin{solution}{{3.17}}
Заметим, что $\Var(u_t|\cF_t)=0$. Более того, для обратимого процесса $\Var(u_t|y_t, y_{t-1}, \ldots, y_1) \approx \Var(u_t|y_t, y_{t-1}, \ldots) = 0$.
\[
\E(y_{101}|y_{100})=7 + 0 + 0.2\E(u_{100}|y_{100})
\]
\[
\E(u_{100}|y_{100}) = \beta_1 + \beta_2 y_{100}
\]
\[
\beta_2 = \frac{\Cov(y_{100}, u_{100})}{\Var(y_{100})}=4/4.16, \beta_1 = \E(u_{100}) - \beta_2 \E(y_{100})=-4\cdot 7/4.16
\]
\[
\frac{y_t}{1+0.2L} = \frac{7}{1+0.2L} + u_t
\]
Заметим, что $\frac{7}{1+0.2L}=7/1.2$, так как $L\cdot 7 = 7$ (вчера семь равнялось семи).

По условию $\frac{y_{100}}{1+0.2L} \approx 5.6$. Знак «примерно равно» возникает из-за замены бесконечной суммы на конечную.

\end{solution}
\protect \hypertarget {soln:3.18}{}
\begin{solution}{{3.18}}
    $\E(y_1)=0$, $\Var(y_1)=\sigma^2_u/(1-\beta^2)$, $\E(y_t|y_{t-1})=\beta y_{t-1}$, $\Var(y_t|y_{t-1})=\sigma^2_u$.

    При максимизации условного правдоподобия получаем:
    \[
         \hb = \frac{y_1 y_2 + y_2 y_3}{y_1^2 + y_2^2}
    \]
  
\end{solution}
\protect \hypertarget {soln:3.19}{}
\begin{solution}{{3.19}}
  
\end{solution}
\protect \hypertarget {soln:3.20}{}
\begin{solution}{{3.20}}
  
\end{solution}
\protect \hypertarget {soln:3.21}{}
\begin{solution}{{3.21}}
    \[
    \plim \hat \beta_2 = \frac{\beta + \alpha}{1 + \beta \alpha}
    \]
  
\end{solution}
\protect \hypertarget {soln:3.22}{}
\begin{solution}{{3.22}}
Если обозначить отношение дисперсий буквой $R = \sigma^2_w/\sigma^2_u$,
то равенство дисперсии и ковариации даёт систему уравнений:
\[
  \begin{cases}
    \alpha R = 2 \\
    (1+\alpha^2)R = 5 \\
  \end{cases}
\]
Решений у неё два, старый процесс $(\alpha=2, R=1)$, и новый $(\alpha=0.5, R=4)$.
Из равенства ожиданий следует, что $c=5$.
  
\end{solution}
\protect \hypertarget {soln:3.23}{}
\begin{solution}{{3.23}}
    Берем любое $a_0$, а дальше в обе стороны заполняем числа по принципу $a_t = -0.5 a_{t-1}$.
  
\end{solution}
\protect \hypertarget {soln:3.24}{}
\begin{solution}{{3.24}}
\textbf{1.}

Пусть $(u_t)$ -- белый шум, рассмотрим следующий процесс:
\[
    w_t = (1 + 2L) (1 - 0.5L + 0.5^2 L^2 - 0.5^3 L^3+ \ldots)u_t
\]

У такого уравнения существует бесконечно много нестационарных решений, но если процесс $(w_t)$ стационарен, то он является белым шумом. Чтобы показать это, выпишем сначала определение белого шума, а затем проверим все ли свойства выполняются для $(w_t)$.
\[
    (u_t) \text{ -- белый шум} \quad \Leftrightarrow \quad  
    \left\{\begin{aligned}
        &\ \E{u_t} = 0 \\
        &\Var{u_t} = \sigma^2 \\
        &\Cov{u_t}{u_s} = 0 \quad \forall s \neq t
    \end{aligned}\right.
\]

Преобразуем выражение для $w_t$:
\begin{align*}
    w_t =& (1 + 2L) (1 - 0.5L + 0.5^2 L^2 - 0.5^3 L^3+ \ldots)u_t \\ \\
    &\quad \Rightarrow \quad w_t = \frac{1 + 2L}{1 - 0.5L}\cdot u_t \\
    &\quad \Rightarrow \quad (1 - 0.5L)w_t = (1 + 2L) u_t \\
    &\quad \Rightarrow \quad w_t - 0.5w_{t-1} = u_t + 2u_{t+1} \\
    &\quad \Rightarrow \quad w_t = u_t + 2u_{t+1} + 0.5w_{t-1}
\end{align*}

Считаем, что процесс $(w_t)$ является стационарным, то есть для него выполняется:
\[
    \left\{\begin{aligned}
        &\E{w_t} = \mu \\
        &\Var{w_t} = \sigma_w^2 \\
        &\Cov{w_t}{w_{t-k}} = \gamma_k \quad \forall k
    \end{aligned}\right.
\]

Теперь наконец найдём мат.ожидание $w_t$ используя выписанные выше свойства процессов $(u_t)$ и $(w_t)$.
\begin{gather*}
    \E{w_t} = \E{u_t + 2u_{t+1} + 0.5w_{t-1}} = \E{u_t} + 2\cdot \E{u_{t+1}} + 0.5\cdot \E{w_{t-1}} = 0.5\cdot \E{w_t} \quad \Rightarrow \quad \E{w_t} = 0
\end{gather*}

Из стационарности $(w_t)$ дисперсия $\Var{w_t}$ уже не зависит от $t$, следовательно, второе свойство из системы для белого шума тоже выполняется. Осталось найти коварицию $w_t$ и $w_{t-k}$ для произвольного $k$ и показать, что она равна 0, сделаем это с помощью индукции. Тогда базой является следующее равенство:
\[
    \Cov{w_t}{w_{t-1}} = 0
\]

Раскроем коварицию и покажем, что это выполняется.
\begin{align*}
    \Cov{w_t}{w_{t-1}} &= \Cov{(1 + 2L) (1 - 0.5L + 0.5^2 L^2 - \ldots)u_t}{(1 + 2L) (1 - 0.5L + 0.5^2 L^2 - \ldots)u_{t-1}} = \\
    &= \Cov{u_t + (2 - 0.5)u_{t-1} + (-1 +0.5^2)u_{t-2} + \ldots}{u_{t-1} + (2 - 0.5)u_{t-2} + \ldots} = \\
    &= \left((2 - 0.5) + (-1 + 0.5^2)(2 - 0.5) + (0.5 - 0.5^3)(-1 + 0.5^2) + \ldots\right) \sigma^2 = \\
    &= \left((2 - 0.5) + \sum_{i = 0}^{\infty}(-1 + 0.5^2)\cdot (-0.5)^i \cdot (2 - 0.5) \cdot (-0.5)^i\right) \sigma^2 = \\
    &= \left((2 - 0.5) - (1 - 0.5^2)(2 - 0.5)\cdot \sum_{i = 0}^{\infty}(-0.5^2)^i\right) \sigma^2 = \\
    &= \left((2 - 0.5) - \cancel{(1 - 0.5^2)}(2 - 0.5)\cdot \frac{1}{\cancel{(1 - 0.5^2)}}\right) \sigma^2 = \\
    &= \big((2 - 0.5) - (2 - 0.5)\big) \sigma^2 = 0 \\
\end{align*}

Теперь докажем шаг индукции. Пусть для $k-1 > 0$ верно, что $\Cov{w_t}{w_{t-(k-1)}} = 0$, выведем аналогичное утверждение для $k$.
\begin{align*}
    \Cov{w_t}{w_{t-k+1}} &= \Cov{w_t}{u_{t-k+1} + 2u_{t-k+2} + 0.5w_{t-k}} = \\
    &= \Cov{w_t}{u_{t-k+1} + 2u_{t-k+2}} + 0.5 \cdot \Cov{w_t}{w_{t-k}} \\ \\
    \Cov{w_t}{u_{t-k+1} + 2u_{t-k+2}} &= \Cov{(1 + 2L) (1 - 0.5L + 0.5^2 L^2 - \ldots)u_t}{u_{t-k+1} + 2u_{t-k+2}} = \\
    &= \Cov{u_t + (2 - 0.5)u_{t-1} + (-1 +0.5^2)u_{t-2} + \ldots}{u_{t-k+1} + 2u_{t-k+2}} = \\
    &= \sum_{i=0}^{\infty} \Cov{(2 - 0.5) \cdot (-0.5)^i u_{t-i-t}}{u_{t-k+1} + 2u_{t-k+2}} = \\
    &= \left[\begin{aligned}
        t - i - 1 = t - k + 1 \quad \Rightarrow \quad i = k - 2 \\
        t - i - 1 = t - k + 2 \quad \Rightarrow \quad i = k - 3 \\
    \end{aligned}\right] = \\
    &= (2 - 0.5) \cdot (-0.5)^{k-2} \sigma^2 + (2 - 0.5) \cdot (-0.5)^{k-3}\cdot 2 \sigma^2 = \\
    &= (2 - 0.5) \cdot (-0.5)^{k-2} \sigma^2 \left(1 - 0.5 \cdot 2\right) = 0 \\ \\
    \Rightarrow \quad \Cov{w_t}{w_{t-k}} &= 2\big(\Cov{w_t}{w_{t-k+1}} - \Cov{w_t}{u_{t-k+1} + 2u_{t-k+2}}\big) = 0
\end{align*}

Значит, третье свойство из системы для белого шума тоже выполняется, и $(w_t)$ действительно является белым шумом. Но опять же только если он стационарен, в другом случае решений бесконечно много и ни одно из них не является белым шумом, так как не стационарно.

\textbf{2.}

Как можно видеть из доказательства выше, умножение или деление на $(1 + \alpha L)$ для любого $|\alpha| \neq 1$ сохраняет белый шум. Аналогичное верно и для умножения или деления на $(1 + \alpha F)$ для любого $|\alpha| \neq 1$, это показывалось на лекциях, но можно и по аналогии с $L$ доказать. Тогда белым шумом являются и следующие стационарные процессы:
\begin{gather*}
    y_t = \frac{(1 + 0.2F)}{(1 + 0.3F)} u_t = (1 + 0.2F)(1 + 0.3F + 0.3^2F^2 + 0.3^3 F^3 + \ldots) u_t\\
    v_t = (1 - 3L)(1 + 0.2 F) u_t = (1 - 3L + 0.2F - 0.6LF)u_t = (0.4 - 3L + 0.2F) u_t
\end{gather*}
  
\end{solution}
\protect \hypertarget {soln:3.25}{}
\begin{solution}{{3.25}}
    $\Corr(y_t, y_{t+1}) \in [-0.5; 0.5]$, $\pCorr(y_t, y_{t+2} ; y_{t+1}) \in [-1; 1/3]$
  
\end{solution}
\protect \hypertarget {soln:3.26}{}
\begin{solution}{{3.26}}
    Процессы $\Delta b_t$, $\Delta_{12} a_t$, $\Delta_{12} b_t$ — стационарные.
    Превратить сезонное случайное блуждание в стационарный процесс взятием обычной разности не получится.
  
\end{solution}
\protect \hypertarget {soln:3.27}{}
\begin{solution}{{3.27}}
  
\end{solution}
\protect \hypertarget {soln:3.28}{}
\begin{solution}{{3.28}}
  
\end{solution}
\protect \hypertarget {soln:4.1}{}
\begin{solution}{{4.1}}
  \[
    \hat y_{4|3} = l_3
  \]
  \[
    y_4 - \hat y_{4|3} = l_3 + \varepsilon_4 - l_3 = \varepsilon_4
  \]
  \[
  \Var(y_4 - \hat y_{4|3} \mid \mathcal{F}_3) = \Var(\varepsilon_4 \mid \mathcal{F}_3) = \Var(\varepsilon_4)
  \]
  \[
  \hat y_{5|3} = l_3
  \]
  \begin{multline}
  y_5 - \hat y_{5|3} = l_4  + \varepsilon_5 - l_3  = (l_3 + \alpha \varepsilon_4)  +
   \varepsilon_5 - l_3 = \\
  = \varepsilon_5 + \alpha  \varepsilon_4
  \end{multline}
  \[
  \Var(y_5 - \hat y_{5|3} \mid \mathcal{F}_3) = \Var(\varepsilon_5 + \alpha  \varepsilon_4 )
  \]

\end{solution}
\protect \hypertarget {soln:4.2}{}
\begin{solution}{{4.2}}
\[
\hat y_{4|3} = l_3 + b_3
\]
\[
y_4 - \hat y_{4|3} = l_3 + b_3 + \varepsilon_4 - (l_3 + b_3) = \varepsilon_4
\]
\[
\Var(y_4 - \hat y_{4|3} \mid \mathcal{F}_3) = \Var(\varepsilon_4 \mid \mathcal{F}_3) = \Var(\varepsilon_4)
\]
\[
\hat y_{5|3} = l_3 + 2b_3
\]
\begin{multline}
y_5 - \hat y_{5|3} = l_4 + b_4 + \varepsilon_5 - (l_3 + 2b_3) = (l_3 + b_3 + \alpha \varepsilon_4)  +
(b_3 + \beta \varepsilon_4) + \varepsilon_5 - (l_3 + 2b_3) = \\
= \varepsilon_5 + (\alpha + \beta) \varepsilon_4
\end{multline}
\[
\Var(y_5 - \hat y_{5|3} \mid \mathcal{F}_3) = \Var(\varepsilon_5 + (\alpha + \beta) \varepsilon_4 )
\]
\end{solution}
\protect \hypertarget {soln:4.3}{}
\begin{solution}{{4.3}}
\end{solution}
\protect \hypertarget {soln:4.4}{}
\begin{solution}{{4.4}}
\end{solution}
\protect \hypertarget {soln:4.5}{}
\begin{solution}{{4.5}}
Для начала запишем уравнения для ETS-AAN модели в общем виде:
\[
    \left\{\begin{aligned}
        u_t &\sim \mathcal{N}(0, \sigma^2), \quad iid \\
        b_t &= b_{t-1} + \beta u_t \\
        l_t &= l_{t-1} + b_{t-1} + \alpha u_t \\
        y_t &= l_{t-1} + b_{t-1} + u_t
    \end{aligned}\right.
\]

Теперь подставим известные параметры и начальные значения:
\[
    \left\{\begin{aligned}
        u_t &\sim \mathcal{N}(0, 16), \quad iid \\
        b_t &= b_{t-1} + \frac{3}{4} \cdot u_t && b_{99}=1 \\
        l_t &= l_{t-1} + b_{t-1} + \frac{1}{2} \cdot u_t \qquad \qquad && l_{99}=8 \\
        y_t &= l_{t-1} + b_{t-1} + u_t && y_{99}=10, \ y_{100}=8
    \end{aligned}\right.
\]

\textbf{1.}

Пользуясь этим уравнениям, найдём искомые $l_{100}$, $b_{100}$, $l_{98}$ и $b_{98}$:
\begin{align*}
    y_{100} = l_{99} + b_{99} + u_{100} \quad &\Rightarrow \quad u_{100} = y_{100} - l_{99} - b_{99} = 8 - 8 - 1 = -1 \\
    &\Rightarrow \quad l_{100} = l_{99} + b_{99} + \frac{1}{2} \cdot u_{100} = 8 + 1 - \frac{1}{2} = 8.5 \\
    &\Rightarrow \quad b_{100} = b_{99} + \frac{3}{4} \cdot u_{100} = 1 - \frac{3}{4} = \frac{1}{4} = 0.25\\
\end{align*}
\[
    \left\{\begin{aligned}
        b_{99} &= b_{98} + \frac{3}{4} \cdot u_{99} \\
        l_{99} &= l_{98} + b_{98} + \frac{1}{2} \cdot u_{99} \\
        y_{99} &= l_{98} + b_{98} + u_{99}
    \end{aligned}\right.
\]
\begin{align*}
    &\Rightarrow \quad b_{98} = b_{99} - \frac{3}{4} \cdot u_{99} \\
    &\Rightarrow \quad l_{99} = l_{98} + b_{99} - \frac{3}{4} \cdot u_{99} + \frac{1}{2} \cdot u_{99} =  l_{98} + b_{99} - \frac{1}{4} \cdot u_{99} \\
    &\Rightarrow \quad l_{98} = l_{99} - b_{99} + \frac{1}{4} \cdot u_{99} \\
    &\Rightarrow \quad y_{99} = l_{99} - b_{99} + \frac{1}{4} \cdot u_{99} + b_{99} - \frac{3}{4} \cdot u_{99} + u_{99} = l_{99} + \frac{1}{2} \cdot u_{99} \\
    &\Rightarrow \quad u_{99} = 2 \cdot (y_{99} - l_{99}) = 2 \cdot (10 - 8) = 4 \\
    &\Rightarrow \quad b_{98} = b_{99} - \frac{3}{4} \cdot u_{99} = 1 - \frac{3}{4} \cdot 4 = -2 \\
    &\Rightarrow \quad l_{98} = l_{99} - b_{99} + \frac{1}{4} \cdot u_{99} = 8 - 1 + \frac{1}{4} \cdot 4 = 8\\
\end{align*}

Итак, ответ в этом пункте:
\[
    l_{100} = 8.5, \qquad b_{100} = 0.25, \qquad l_{98} = 8, \qquad b_{98} = -2
\]

\textbf{2.}

Точечный прогноз $\hat{y}_{101 \mid 100}$ равен мат.ожиданию $y_{101}$ при условии всей информации $\mathcal{F}_{100}$, которую мы знаем на шаге 100, а именно:
\[
    \hat{y}_{101 \mid 100} = \E{y_{101} \mid \mathcal{F}_{100}} = \E{l_{100} + b_{100} + u_{101}} = l_{100} + b_{100} = 8.5 + 0.25 = 8.75
\]

Аналогично найдём $\hat{y}_{102 \mid 100}$:
\begin{align*}
    \hat{y}_{102 \mid 100} &= \E{y_{102} \mid \mathcal{F}_{100}} = \E{l_{101} + b_{101} + u_{102}} = \E{l_{101}} + \E{b_{101}} = \\ &= \E{l_{100} + b_{100} + \frac{1}{2} \cdot u_{101}} + \E{b_{100} + \frac{3}{4} \cdot u_{101}} = \\
    &= l_{100} + b_{100} + b_{100} = 8.5 + 0.25 + 0.25 = 9
\end{align*}

\textbf{3.} 

В общем виде 95\% предиктивные интервалы для $y_{101}$ и $y_{102}$ вычисляются по следующим формулам соответственно:
\begin{gather*}
    y_{101} \in \left[\E{y_{101} \mid \mathcal{F}_{100}} - 1.96 \sqrt{\Var{y_{101} \mid \mathcal{F}_{100}}},\ \  \E{y_{101} \mid \mathcal{F}_{100}} + 1.96 \sqrt{\Var{y_{101} \mid \mathcal{F}_{100}}}\right] \\
    y_{102} \in \left[\E{y_{102} \mid \mathcal{F}_{100}} - 1.96 \sqrt{\Var{y_{102} \mid \mathcal{F}_{100}}},\ \  \E{y_{102} \mid \mathcal{F}_{100}} + 1.96 \sqrt{\Var{y_{102} \mid \mathcal{F}_{100}}}\right]
\end{gather*}

Значит, нам осталось найти только дисперсии $y_{101}$ и $y_{102}$ при условии всё той же информации $\mathcal{F}_{100}$:
\begin{align*}
    \Var{y_{101} \mid \mathcal{F}_{100}} &= \Var{l_{100} + b_{100} + u_{101}} = \Var{u_{101}} = 16 \\
    \Var{y_{102} \mid \mathcal{F}_{100}} &= \Var{l_{101} + b_{101} + u_{102}} = \Var{l_{100} + b_{100} + \frac{1}{2} \cdot u_{101} + b_{100} + \frac{3}{4} \cdot u_{101} + u_{102}} = \\
    &= \Var{\frac{5}{4} \cdot u_{101} + u_{102}} = \frac{25}{16} \cdot \Var{u_{101}} + \Var{u_{102}} = \frac{25}{16} \cdot 16 + 16 = 41
\end{align*}

Значит, 95\% предиктивные интервалы для $y_{101}$ и $y_{102}$ следующие:
\[
\begin{aligned}
    y_{101} &\in \big[8.75 - 1.96 \cdot 4; 8.75 + 1.96 \cdot 4\big] \\
    y_{102} &\in \big[9 - 1.96 \cdot \sqrt{41}; 9 + 1.96 \cdot \sqrt{41}\big]
\end{aligned}
\quad \Rightarrow \quad
\begin{aligned}
    y_{101} &\in \big[0.91; 16.59\big] \\
    y_{102} &\in \big[-3.55; 21.55\big]
\end{aligned}
\]

\end{solution}
\protect \hypertarget {soln:4.6}{}
\begin{solution}{{4.6}}
^^I\begin{enumerate}
^^I^^I\item Простое экспоненциальное сглаживание, ETS-ANN; ARIMA(0,1,1)
^^I^^I\item Аддитивное сглаживание Хольта, ETS-AAN; ARIMA(0,2,2)
^^I^^I\item Аддитивное сглаживание Хольта с угасающим трендом, ETS-AAdN; ARIMA(1,1,2)
^^I^^I\item Аддитивное сглаживание Хольта-Винтерса для месячных данных, ETS-AAA; ARIMA(0,1,13)-SARIMA(0,1,0)
^^I^^I\item Аддитивное сглаживание Хольта-Винтерса с угасающим трендом для месячных данных, ETS-AAdA; ARIMA(0,1,13)-SARIMA(0,1,0)
^^I^^I\item ETS-ANA; ARIMA(0,1,12)-SARIMA(0,1,0)
^^I\end{enumerate}
\end{solution}
\protect \hypertarget {soln:4.7}{}
\begin{solution}{{4.7}}
По $l_0$, $b_0$;
\end{solution}
\protect \hypertarget {soln:4.8}{}
\begin{solution}{{4.8}}
  Только примерно, $\ln (1 + x) \approx x$.
\end{solution}
\protect \hypertarget {soln:4.9}{}
\begin{solution}{{4.9}}
\end{solution}
\protect \hypertarget {soln:4.10}{}
\begin{solution}{{4.10}}
Выпишем модель $ETS(AAN)$ в общем виде:
\[
    \left\{\begin{aligned}
        u_t &\sim \mathcal{N}(0, \sigma^2), \quad iid \\
        b_t &= b_{t-1} + \beta u_t \\
        l_t &= l_{t-1} + b_{t-1} + \alpha u_t \\
        y_t &= l_{t-1} + b_{t-1} + u_t
    \end{aligned}\right.
\]

Для начала выпишем выражение для $b_t$:
\[
    b_t = b_{t-1} + \beta u_t = b_0 + \beta(u_1 + \ldots + u_t) = b_0 + \sum_{i = 1}^t \beta u_i
\]

Также из последнего уравнения модели можно видеть. что $y_t$ выражается через сумму $l_{t-1} + b_{t-1}$. Значит, чтобы в дальнейшем посчитать требуемые $\E{y_t}$, $\Var{y_t}$, $\Cov{y_t}{y_{t-1}}$, нужно привести эту сумму к известным нам величинам: $l_0$, $b_0$, $\alpha$, $\beta$ и сумме некоторых $u_s$, для которых все эти величины мы можем найти, поскольку знаем их распределение. Докажем по индукции, что для $l_{t} + b_{t}$ верно равенство:
\begin{align*}
    l_{t} + b_{t} 
    &= l_0 + (t + 1) b_0 + (\alpha + t\beta) u_1 + \ldots + (\alpha + 2\beta) u_{t-1} + (\alpha + \beta) u_t = \\
    &= l_0 + (t + 1) b_0 + \sum_{i = 1}^t \big(\alpha + (t - i + 1)\beta\big) u_i
\end{align*}

Шаг индукции для $t = 1$ доказывается просто:
\[
    l_1 + b_1 = (l_0 + b_0 + \alpha u_1) + (b_0 + \beta u_1) = l_0 + 2 b_0 + (\alpha + \beta) u_1
\]

Теперь докажем шаг индукции: предположим, что для $t - 1$ такая формула верна, и выразим через неё аналогичную для $t$.
\begin{align*}
l_{t-1} + b_{t-1} &= l_0 + t b_0 + \sum_{i = 1}^{t-1} \big(\alpha + (t - i)\beta\big) u_i \\
    l_t + b_t &= (l_{t-1} + b_{t-1} + \alpha u_t) + (b_{t-1} + \beta u_t) = \big(l_{t-1} + b_{t-1}\big) + b_{t-1} + (\alpha + \beta) u_t = \\
    &= \Big( l_0 + t b_0 + \sum_{i = 1}^{t-1} \big(\alpha + (t - i)\beta\big) u_i \Big) + b_{t-1} + (\alpha + \beta) u_t = \\
    &= \Big( l_0 + t b_0 + \sum_{i = 1}^{t-1} \big(\alpha + (t - i)\beta\big) u_i \Big) + b_0 + \sum_{i = 1}^{t-1} \beta u_i + (\alpha + \beta) u_t = \\
    &= l_0 + (t + 1) b_0 + \sum_{i = 1}^{t-1} \Big(\big(\alpha + (t - i)\beta\big) u_i + \beta u_i \Big) + (\alpha + \beta) u_t = \\
    &= l_0 + (t + 1) b_0 + \sum_{i = 1}^{t-1} \big(\alpha + (t - i + 1)\beta\big) u_i + (\alpha + \beta) u_t = \\
    &= l_0 + (t + 1) b_0 + \sum_{i = 1}^{t} \big(\alpha + (t - i + 1)\beta\big) u_i \\
    &&\blacksquare
\end{align*}

Теперь с помощью этой формулы можем найти все требуемые величины.
\[
    \E{y_t} = \E{l_{t-1} + b_{t-1} + u_t} = \E{l_{t-1} + b_{t-1}} = \E{l_0 + t b_0 + \sum_{i = 1}^{t-1} \big(\alpha + (t - i)\beta\big) u_i} = \E{l_0 + t b_0} = l_0 + tb_0 \\
\]
\begin{align*}
    \Var{y_t} &= \Var{l_{t-1} + b_{t-1} + u_t} + \Var{l_0 + t b_0 + \sum_{i = 1}^{t-1} \big(\alpha + (t - i)\beta\big) u_i + u_t} = \\
    &= \sum_{i = 1}^{t-1}\big(\alpha + (t - i)\beta\big)^2 \Var{ u_i } + \Var{u_t} = \sum_{i = 1}^{t-1}\big(\alpha + (t - i)\beta\big)^2 \sigma^2 + \sigma^2 = \\
    &= \Big[k = t - i\Big]= \left( 1 + \sum_{k = 1}^{t-1}\big(\alpha + k\beta\big)^2 \right)\sigma^2 \\
\end{align*}

\begin{align*}
    \Cov{y_t}{y_{t+1}} &= \Cov{l_{t-1} + b_{t-1} + u_t}{l_{t} + b_{t} + u_{t+1}} = \\
    &= \Cov{l_0 + t b_0 + \sum_{i = 1}^{t-1} \big(\alpha + (t - i)\beta\big) u_i + u_t}{l_0 + (t+1) b_0 + \sum_{i = 1}^{t} \big(\alpha + (t - i + 1)\beta\big) u_i + u_{t+1}} = \\
    &= \Cov{\sum_{i = 1}^{t-1} \big(\alpha + (t - i)\beta\big) u_i + u_t}{\sum_{i = 1}^{t} \big(\alpha + (t - i + 1)\beta\big) u_i} = \\
    &= \sum_{i = 1}^{t-1} \big(\alpha + (t - i)\beta\big)\big(\alpha + (t - i + 1)\beta\big) \sigma^2 + (\alpha + \beta) \sigma^2 = \\
    &= \left( (\alpha + \beta) + \sum_{i = 1}^{t-1} \big(\alpha + (t - i)\beta\big)\big(\alpha + (t - i + 1)\beta\big) \right)\sigma^2 = \\
    &= \Big[k = t - i\Big]= \left( (\alpha + \beta) + \sum_{k = 1}^{t-1} \big(\alpha + k\beta\big)\big(\alpha + (k + 1)\beta\big) \right)\sigma^2
\end{align*}

\end{solution}
\protect \hypertarget {soln:4.11}{}
\begin{solution}{{4.11}}
\textbf{1.}

Выпишем модель $ETS(AAA)$ для наших значений параметров:
\[
    \left\{\begin{aligned}
        u_t &\sim \mathcal{N}(0, 4), \quad iid \\
        s_t &= s_{t-2} + 0.1 u_t, && s_{99} = -1.9, \ s_{100} = 2\\
        b_t &= b_{t-1} + 0.2 u_t, && b_{100} = 0.5\\
        l_t &= l_{t-1} + b_{t-1} + 0.3 u_t, && l_{100} = 4 \\
        y_t &= l_{t-1} + b_{t-1} + s_{t-2} + u_t
    \end{aligned}\right.
\]

В общем виде 95\% предиктивный интервал для $y_{102}$ вычисляется по формуле:
\[
    y_{102} \in \left[\E{y_{102} \mid \mathcal{F}_{100}} - 1.96 \sqrt{\Var{y_{102} \mid \mathcal{F}_{100}}},\ \  \E{y_{102} \mid \mathcal{F}_{100}} + 1.96 \sqrt{\Var{y_{102} \mid \mathcal{F}_{100}}}\right]
\]

Так что сначала посчитаем мат.ожидание и дисперсию $y_{102}$ при условии информации $\mathcal{F}_{100}$.
\begin{align*}
    \E{y_{102} \mid \mathcal{F}_{100}} &= \E{l_{101} + b_{101} + s_{100} + u_{102} \mid \mathcal{F}_{100}} = \\
    &= \E{l_{100} + 2b_{100} + s_{100} \mid \mathcal{F}_{100}} = \\
    &= l_{100} + 2b_{100} + s_{100} = 4 + 2 \cdot 0.5 + 2 = 7 \\ \\
    \Var{y_{102} \mid \mathcal{F}_{100}} &= \Var{l_{101} + b_{101} + s_{100} + u_{102} \mid \mathcal{F}_{100}} = \\
    &= \Var{l_{100} + 2b_{100} + s_{100} + (0.3 + 0.2) u_{101} + u_{102} \mid \mathcal{F}_{100}} = \\
    &= \Var{0.5 u_{101} + u_{102} \mid \mathcal{F}_{100}} = 0.25 \cdot 4 + 4 = 5
\end{align*}

Значит, искомый предиктивный интервал вот такой:
\[
    y_{102} \in \left[7 - 5 \cdot 1.96, \ \ 7 + 5 \cdot 1.96\right] \quad \Rightarrow \quad y_{102} \in \left[-2.8, \ \ 16.8\right]
\]

\textbf{2.}

Чтобы понять, какое количество параметров оценивается в $ETS(AAA)$ модели для полугодовых данных, випишем эту модель в общем виде:
\[
    \left\{\begin{aligned}
        u_t &\sim \mathcal{N}(0, \sigma^2), \quad iid \\
        s_t &= s_{t-2} + \gamma u_t \\
        b_t &= b_{t-1} + \beta u_t \\
        l_t &= l_{t-1} + b_{t-1} + \alpha u_t \\
        y_t &= l_{t-1} + b_{t-1} + s_{t-2} + u_t
    \end{aligned}\right.
\]

В этой системе 4 параметра: $\alpha$, $\beta$, $\gamma$ и $\sigma$. Также для предсказания с помощью такой модели необходимо оценить начальные значения всех составляющих $y_t$: $l_0$, $b_0$, $s_0$, $s_{-1}$. При этом на начальные значения $s_i$ у нас есть дополнительное условие:
\[
    \sum_{i} s_i = 0 \quad \Rightarrow \quad s_{-1} + s_0 = 0
\]

Следовательно, нужно оценить только 7 параметров, поскольку $s_0$ однозначно выражается через $s_{-1}$ и его не нужно отдельно оценивать.


\end{solution}
\protect \hypertarget {soln:4.12}{}
\begin{solution}{{4.12}}
\end{solution}
\protect \hypertarget {soln:5.1}{}
\begin{solution}{{5.1}}
  $\ln y$
\end{solution}
\protect \hypertarget {soln:6.1}{}
\begin{solution}{{6.1}}
\end{solution}
\protect \hypertarget {soln:6.2}{}
\begin{solution}{{6.2}}
    \begin{enumerate}
      \item Чтобы заниматься математикой по ночам.
      \item За поддержку якобинцев.
      \item Кофейник. Был разбит пулей.
    \end{enumerate}
\end{solution}
\protect \hypertarget {soln:6.3}{}
\begin{solution}{{6.3}}
  
\end{solution}
\protect \hypertarget {soln:6.4}{}
\begin{solution}{{6.4}}
  
\end{solution}
\protect \hypertarget {soln:6.5}{}
\begin{solution}{{6.5}}
  
\end{solution}
\protect \hypertarget {soln:6.6}{}
\begin{solution}{{6.6}}
  
\end{solution}
\protect \hypertarget {soln:6.7}{}
\begin{solution}{{6.7}}
  
\end{solution}
\protect \hypertarget {soln:6.8}{}
\begin{solution}{{6.8}}
   Да, ряды являются ортогональными. Можно строить регрессии на эти регрессоры в любых комбинациях, оценки бет выходят одни и те же.
   Другие ряды добавить нельзя — будет строгая мультиколлинеарность.
 
\end{solution}
\protect \hypertarget {soln:6.9}{}
\begin{solution}{{6.9}}
     На всякий случай, это был ряд $1$, $2$, $3$, $4$, $5$, $6$.
   
\end{solution}
\protect \hypertarget {soln:6.10}{}
\begin{solution}{{6.10}}
   $1$, $1$, $1$, $2$, $2$, $2$
   
\end{solution}
\protect \hypertarget {soln:7.1}{}
\begin{solution}{{7.1}}
\end{solution}
\protect \hypertarget {soln:7.2}{}
\begin{solution}{{7.2}}

\end{solution}
\protect \hypertarget {soln:7.3}{}
\begin{solution}{{7.3}}

\end{solution}
\protect \hypertarget {soln:7.4}{}
\begin{solution}{{7.4}}

\end{solution}
\protect \hypertarget {soln:7.5}{}
\begin{solution}{{7.5}}
$1$, $2$, $2$
\end{solution}
\protect \hypertarget {soln:7.6}{}
\begin{solution}{{7.6}}
\end{solution}
\protect \hypertarget {soln:7.7}{}
\begin{solution}{{7.7}}
\end{solution}
\protect \hypertarget {soln:7.8}{}
\begin{solution}{{7.8}}
\end{solution}
\protect \hypertarget {soln:7.9}{}
\begin{solution}{{7.9}}
\end{solution}
\protect \hypertarget {soln:7.10}{}
\begin{solution}{{7.10}}
Да, может быть и больше, и меньше.
\end{solution}
\protect \hypertarget {soln:7.11}{}
\begin{solution}{{7.11}}

\end{solution}
\protect \hypertarget {soln:7.12}{}
\begin{solution}{{7.12}}
\[
\Var(\e_t | \cF_{t-1}) = \Var(y_t| \cF_{t-1}) = 6 + 0.4 \sigma^2_{t-1} + 0.2\e_t^2
\]
\[
\Var(\e_t) = 6/(1-0.4-0.2)=6/0.4=15
\]
\[
\Var(y_t)=15/(1-0.36)
\]
\end{solution}
\protect \hypertarget {soln:8.1}{}
\begin{solution}{{8.1}}

\begin{enumerate}
\item $H_0$: ряд содержит единичный корень, $\beta=0$; $H_a$: ряд не содержит единичного корня, $\beta<0$
\item $ADF=-0.4/0.1=-4$, $ADF_{crit}=-2.89$, $H_0$ отвергается
\item Ряд стационарен
\item При верной $H_0$ ряд не стационарен, и  $t$-статистика имеет не $t$-распределение, а распределение Дики-Фуллера.
\end{enumerate}
\end{solution}
\protect \hypertarget {soln:9.1}{}
\begin{solution}{{9.1}}

\end{solution}
\protect \hypertarget {soln:9.2}{}
\begin{solution}{{9.2}}

\end{solution}
\protect \hypertarget {soln:9.3}{}
\begin{solution}{{9.3}}

$z_t$ стационарный, $x_t$ и $y_t$ не коинтегрированы
\end{solution}
\protect \hypertarget {soln:9.4}{}
\begin{solution}{{9.4}}

\end{solution}
\protect \hypertarget {soln:9.5}{}
\begin{solution}{{9.5}}
$y_t$ и $s_t$; $z_t$ и $w_t$.
\end{solution}
\protect \hypertarget {soln:9.6}{}
\begin{solution}{{9.6}}
  \begin{enumerate}
    \item $a_t = 0.5 a_{t-1} + u_t$, AR(1)
    \item $b_t = b_{t-1} + u_t$, $b_0 = 0$, ARIMA(0, 1, 0)
    \item $c_t = 0.5 b_t + \e_t$, ARIMA(0, 1, 1)
    \item $d_t = d_{t-1} + a_t$, ARIMA(1, 1, 0)
    \item $e_t = e_{t-1} + \e_t$, ARIMA(0, 1, 0)
    \item $g_t = g_{t-1} + b_t$, ARIMA(0, 2, 0)
    \item $h_t = 0.7 h_{t-1} + b_t$, ARIMA(1, 1, 0)
  \end{enumerate}
  коинтегрированы: $b_t$, $c_t$, $d_t$, $h_t$.
\end{solution}
\protect \hypertarget {soln:9.7}{}
\begin{solution}{{9.7}}
Процессы $y_t$ и $z_t$ коинтегрированы, $z_t - 1.5y_t$ стационарен.
Процессы $y_t$ и $r_t$ коинтегрированы, $r_t + 2y_t$ стационарен.
\end{solution}
\protect \hypertarget {soln:10.1}{}
\begin{solution}{{10.1}}
\end{solution}
\protect \hypertarget {soln:10.2}{}
\begin{solution}{{10.2}}
\end{solution}
\protect \hypertarget {soln:10.3}{}
\begin{solution}{{10.3}}
\end{solution}
\protect \hypertarget {soln:10.4}{}
\begin{solution}{{10.4}}
\end{solution}